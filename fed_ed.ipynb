{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a26882b",
   "metadata": {
    "id": "7a26882b"
   },
   "source": [
    "<H1>Import Libraries</H1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "842480e8-82ff-49a9-a527-d9548975a8e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import copy\n",
    "import random\n",
    "import warnings\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms, models\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from collections import Counter\n",
    "\n",
    "# Plot settings\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "plt.rcParams['font.serif'] = ['Times New Roman'] + plt.rcParams['font.serif']\n",
    "\n",
    "# Ignore warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Reproducibility\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8f95a6",
   "metadata": {},
   "source": [
    "# Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2700fb3",
   "metadata": {
    "id": "f2700fb3"
   },
   "outputs": [],
   "source": [
    "def accuracy(outp, target):\n",
    "    \"\"\"Computes accuracy\"\"\"\n",
    "    with torch.no_grad():\n",
    "        pred = torch.argmax(outp, dim=1)\n",
    "        correct = pred.eq(target).float().sum().item()\n",
    "        return 100.0 * correct / target.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9306ada",
   "metadata": {
    "id": "b9306ada"
   },
   "outputs": [],
   "source": [
    "def Print(string, dictionary):\n",
    "    first_key = next(iter(dictionary))\n",
    "    first_value = dictionary[first_key]\n",
    "    print(f\"{string}:{first_key}: {first_value[0][0]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0db37362",
   "metadata": {
    "id": "0db37362"
   },
   "outputs": [],
   "source": [
    "def forbinus_norm_function(w_i):\n",
    "    value = 0\n",
    "    for k in w_i.keys():\n",
    "        value += torch.linalg.norm(w_i[k])\n",
    "    return value.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e387f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_deviation_function(w_i, w_f):\n",
    "    model_deviation = 0\n",
    "    for k in w_i.keys():\n",
    "        model_deviation += torch.linalg.norm(w_f[k].to(torch.float) - w_i[k].to(torch.float)) / torch.linalg.norm(w_i[k].to(torch.float))\n",
    "    #print(model_deviation.item())\n",
    "    return model_deviation.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53678293",
   "metadata": {
    "id": "53678293"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0a3ffbe",
   "metadata": {
    "id": "e0a3ffbe"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#====CNN model\n",
    "class model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(model, self).__init__()\n",
    "\n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.conv4 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(128 * 8 * 8, 512)  # Adjust input size here\n",
    "        self.relu5 = nn.ReLU()\n",
    "        self.dropout3 = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(512, 10)  # Add a linear layer for classification\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu1(self.conv1(x))\n",
    "        x = self.relu2(self.conv2(x))\n",
    "        x = self.pool1(x)\n",
    "        x = self.dropout1(x)\n",
    "\n",
    "        x = self.relu3(self.conv3(x))\n",
    "        x = self.relu4(self.conv4(x))\n",
    "        x = self.pool2(x)\n",
    "        x = self.dropout2(x)\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.relu5(self.fc1(x))\n",
    "        x = self.dropout3(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7eaf8a",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "833d43d8",
   "metadata": {
    "id": "833d43d8"
   },
   "outputs": [],
   "source": [
    "def train(i_weights, epochs, train_loader, le_rate, cli,roun, epoch_flag):\n",
    "    global opti\n",
    "    local_model = model().to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    # u_le_rate=(le_rate * w_l)\n",
    "    if opti==\"adam\":\n",
    "        optimizer = torch.optim.Adam(local_model.parameters(), lr=le_rate)\n",
    "    elif opti==\"sgd\":\n",
    "        optimizer = torch.optim.SGD(local_model.parameters(), lr=le_rate)\n",
    "    \n",
    "    epoch_train_accuracy=0 \n",
    "    epoch_train_loss=0\n",
    "    epoch_test_accuracy=0\n",
    "    epoch_test_loss=0\n",
    "    epoch_rmd=0\n",
    "\n",
    "    local_model.load_state_dict(i_weights)\n",
    "\n",
    "    local_model.train()  # Set the model to training mode\n",
    "\n",
    "    # initial weights cathing and printing\n",
    "    initial_weights = {k: v.clone() for k, v in local_model.state_dict().items()}\n",
    "    #Print(\"Model's inside the function Initial weights for client\",initial_weights)\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        epoch_flag=epoch_flag+1\n",
    "        # gradients_this_epoch = {}\n",
    "        total_samples = 0\n",
    "        total_loss=0\n",
    "        correct_samples = 0\n",
    "        for i, (inputs, labels) in enumerate(train_loader, 0):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            # Forward + backward + optimize\n",
    "            outputs = local_model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            \n",
    "            # torch.nn.utils.clip_grad_norm_(local_model.parameters(), max_norm=1.0)\n",
    "            total_loss += loss.item()\n",
    "            optimizer.step()\n",
    "\n",
    "            _, predicted = outputs.max(1)  # Get the index of the maximum value in outputs (predicted class)\n",
    "            total_samples += labels.size(0)\n",
    "            correct_samples += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        if(total_samples!=0 and len(train_loader)!=0):\n",
    "            epoch_accuracy = 100 * correct_samples / total_samples\n",
    "            epoch_loss = total_loss / len(train_loader)\n",
    "        else:\n",
    "            epoch_accuracy = 100 * correct_samples / (total_samples+1)\n",
    "            epoch_loss = total_loss / (len(train_loader)+1)\n",
    "        # print(f\"Round {roun}, client {cli}, epoch {epoch}: epoch_accuracy {epoch_accuracy}, epoch_loss {epoch_loss} \")\n",
    "    \n",
    "    f_weights = {k: v.clone() for k, v in local_model.state_dict().items()}\n",
    "\n",
    "    # print(f\"\\n Round {roun}, client {cli+1}: epoch_accuracy {epoch_accuracy}, epoch_loss {epoch_loss} \\n\")\n",
    "    epoch_train_accuracy=epoch_accuracy\n",
    "    epoch_train_loss=epoch_loss\n",
    "    # epoch_test_accuracy, epoch_test_loss= test(f_weights, test_loader)\n",
    "    epoch_test_accuracy, epoch_test_loss= 0,0\n",
    "    \n",
    "    \n",
    "    epoch_rmd= 0# model_deviation_function(initial_weights,f_weights)\n",
    "    \n",
    "    #saving data into dataframe\n",
    "    epoch_data = [roun, cli, epoch_train_accuracy, epoch_train_loss, epoch_test_accuracy, epoch_test_loss, epoch_rmd]\n",
    "    epoch_results.loc[len(epoch_results)] = epoch_data\n",
    "    \n",
    "    return epoch_accuracy,epoch_loss, f_weights, epoch_flag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b882b03e",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d5cef1c",
   "metadata": {
    "id": "9d5cef1c"
   },
   "outputs": [],
   "source": [
    "def test(w,data):\n",
    "    lmodel = model().to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    lmodel.load_state_dict(w)\n",
    "    lmodel.eval()\n",
    "\n",
    "    # Evaluation phase for test set\n",
    "    acc_list = []\n",
    "    loss_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for j, data in enumerate(data, 0):\n",
    "            images, labels = data\n",
    "            images = images.cuda()\n",
    "            labels = labels.cuda()\n",
    "            out = lmodel(images)\n",
    "            # Calculate loss\n",
    "            loss = criterion(out, labels)\n",
    "            loss_list.append(loss.item())\n",
    "            #calculate accuracy\n",
    "            acc = accuracy(out, labels)\n",
    "            acc_list.append(acc)\n",
    "    test_loss = np.mean(loss_list)\n",
    "    test_accuracy = np.mean(acc_list)\n",
    "    return test_accuracy, test_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba1aae2",
   "metadata": {},
   "source": [
    "# FL Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69e2310e-1d75-4f4f-84f7-e9b60bf0daf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_flri(client_updates, client_weights):\n",
    "    \"\"\"\n",
    "    client_updates: list of model update tensors (delta_w_k), flattened\n",
    "    client_weights: list of weights (alpha_k), usually n_k / total_n\n",
    "    \"\"\"\n",
    "    assert len(client_updates) == len(client_weights), \"Mismatch between updates and weights\"\n",
    "\n",
    "    # Compute the weighted average update\n",
    "    avg_update = sum(w * u for w, u in zip(client_weights, client_updates))\n",
    "\n",
    "    def cosine_sim(a, b):\n",
    "        return torch.nn.functional.cosine_similarity(a, b, dim=0)\n",
    "\n",
    "    # Compute weighted disagreement\n",
    "    rosa_t = 0.0\n",
    "    for w_k, delta_k in zip(client_weights, client_updates):\n",
    "        sim = cosine_sim(delta_k, avg_update)\n",
    "        rosa_t += w_k * (1 - sim)\n",
    "    \n",
    "    return rosa_t.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41a1ce24-8763-423c-a50c-fb31c32b97a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def fed_avg(client_weights_list):\n",
    "#     \"\"\"\n",
    "#     Plain averaging of client weights (no weighting by client sizes).\n",
    "#     client_sizes argument is ignored.\n",
    "#     \"\"\"\n",
    "#     num_clients = len(client_weights_list)\n",
    "#     if num_clients == 0:\n",
    "#         raise ValueError(\"No client weights provided\")\n",
    "\n",
    "#     agg_weights = {}\n",
    "#     for key in client_weights_list[0].keys():\n",
    "#         agg_weights[key] = torch.zeros_like(client_weights_list[0][key], dtype=torch.float32)\n",
    "\n",
    "#     for weights in client_weights_list:\n",
    "#         for key in agg_weights.keys():\n",
    "#             agg_weights[key] += weights[key].float()\n",
    "\n",
    "#     for key in agg_weights.keys():\n",
    "#         agg_weights[key] /= num_clients  # divide by number of clients\n",
    "\n",
    "#     return agg_weights\n",
    "\n",
    "def euclidean_averaging(dicts, base_weights):\n",
    "    # Initialize an empty dictionary to store the averaged weights\n",
    "    averaged_weights = {}\n",
    "\n",
    "    # Iterate through the base weights to calculate the Euclidean average\n",
    "    for key in base_weights.keys():\n",
    "        weight_sums = torch.zeros_like(base_weights[key]).float()  # Initialize with zeros on the same device and in float type\n",
    "        weight_norms = torch.zeros_like(base_weights[key]).float()  # Initialize with zeros on the same device and in float type\n",
    "        \n",
    "        # Calculate the Euclidean distance for each client model's weight compared to the base\n",
    "        for client_weights in dicts:\n",
    "            client_weights[key] = client_weights[key].float()  # Ensure tensor is on the same device and in float\n",
    "            base_weights[key] = base_weights[key].float()  # Ensure tensor is on the same device and in float\n",
    "            distance = torch.norm(client_weights[key] - base_weights[key], p=2)\n",
    "            weight = 1 / (distance + 1e-5)  # Small stabilizer to avoid division by zero\n",
    "            weight_sums += client_weights[key] * weight\n",
    "            weight_norms += weight\n",
    "        \n",
    "        # Average the weights\n",
    "        averaged_weights[key] = weight_sums / weight_norms\n",
    "    \n",
    "    return averaged_weights\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1c83699-e8fd-4ba6-9741-45f831d5ea8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_model_update(update_dict):\n",
    "    \"\"\"\n",
    "    Convert a dict of parameter tensors (model state dict differences)\n",
    "    to one 1D flattened tensor.\n",
    "    \"\"\"\n",
    "    flat_params = []\n",
    "    for key in update_dict:\n",
    "        flat_params.append(update_dict[key].flatten())\n",
    "    return torch.cat(flat_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0d35af3",
   "metadata": {
    "id": "c0d35af3"
   },
   "outputs": [],
   "source": [
    "def federated_learning(i_w, data_client, C, P, R, E, learning_rate, b_size):\n",
    "    \n",
    "    global total_clients_list, participating_client_list, val_loader, folder_name, norms_results\n",
    "    \n",
    "    global_model.load_state_dict(i_w)\n",
    "    #Print(\"Model's initial weights\", i_w)\n",
    "    r_flag=0\n",
    "    # weights = [1] * C\n",
    "    global delta_ad\n",
    "    global weight_c\n",
    "    # client_sizes=[1]*P\n",
    "\n",
    "    #loop for round\n",
    "    for r in range(1,R+1):\n",
    "        round_train_accuracy=0\n",
    "        round_train_loss=0\n",
    "        round_test_accuracy=0\n",
    "        round_test_loss=0\n",
    "        epoch_flag=0\n",
    "\n",
    "        #saving initial weights for spiking model\n",
    "        i_w = {k: v.clone() for k, v in global_model.state_dict().items()}\n",
    "        #Print(\"Model's initial weights\", i_w)\n",
    "        \n",
    "        #colleting weights and results\n",
    "        all_final_weights={}\n",
    "        train_accuracy_list=[]\n",
    "        train_loss_list=[]\n",
    "\n",
    "        update_list=[]\n",
    "        weight_list=[]\n",
    "        client_sizes = []\n",
    "        \n",
    "        # Randomly select clients\n",
    "        selected_clients = random.sample(total_clients_list, P)\n",
    "        participating_client_list.append(selected_clients)\n",
    "\n",
    "        #loop for client\n",
    "        for c, data in enumerate(data_client):\n",
    "            \n",
    "            if(c in selected_clients):\n",
    "                train_loader = torch.utils.data.DataLoader(data, batch_size=b_size, shuffle=True)\n",
    "                \n",
    "                train_accuracy, train_loss, c_f_weights, epoch_flag = train(i_w, E, train_loader, learning_rate, c, r, epoch_flag)\n",
    "                \n",
    "                train_accuracy_list.append(train_accuracy)\n",
    "                train_loss_list.append(train_loss)\n",
    "\n",
    "                model_update = {}\n",
    "                for key in global_model.state_dict():\n",
    "                    model_update[key] = torch.sub(c_f_weights[key], i_w[key])\n",
    "                \n",
    "                update_list.append(model_update)\n",
    "                weight_list.append(c_f_weights)\n",
    "                client_sizes.append(1)\n",
    "\n",
    "            else:\n",
    "                print(f\"client {c} is not selectecd\")\n",
    "        \n",
    "        # #calcualting AD\n",
    "        # ad_c_list = []\n",
    "        # num_participants = len(update_list)\n",
    "        # for i in range(num_participants):\n",
    "        #     dists = []\n",
    "        #     for j in range(num_participants):\n",
    "        #         if i != j:\n",
    "        #             diff = 0.0\n",
    "        #             for key in update_list[i]:\n",
    "        #                 # diff += torch.norm(update_list[i][key] - update_list[j][key], p=2).item() ** 2\n",
    "        #                 diff += torch.norm(update_list[i][key].float() - update_list[j][key].float(), p=2).item() ** 2\n",
    "\n",
    "        #             dists.append(diff)\n",
    "        #     ad_c = sum(dists) / (num_participants - 1)\n",
    "        #     ad_c_list.append(ad_c)\n",
    "        # delta_ad[f\"round_{r}\"]=(ad_c_list, r)\n",
    "\n",
    "        #list and round counter\n",
    "        round_epoch=(epoch_flag)\n",
    "        \n",
    "        #print(\"Total number of selected clients is\", client_counter)\n",
    "        round_train_loss=sum(train_loss_list)/len(train_loss_list)\n",
    "        round_train_accuracy=sum(train_accuracy_list)/len(train_accuracy_list)\n",
    "\n",
    "        print(f\"\\n\\n Model's Round: {r}, train accuracy of model: {round_train_accuracy}, train loss of model: {round_train_loss}\")\n",
    "\n",
    "        # FedAvg aggregation\n",
    "        all_final_weights = euclidean_averaging(weight_list, i_w)\n",
    "        # fed_avg(weight_list)\n",
    "        \n",
    "        # flat_updates = [flatten_model_update(update) for update in update_list]\n",
    "\n",
    "        # total_samples = sum(client_sizes)\n",
    "        # client_weights = [size / total_samples for size in client_sizes]\n",
    "\n",
    "        # flri=calculate_flri(flat_updates, client_weights)\n",
    "        flri=0\n",
    "        # print(f\"round {r} = flri {flri}\")\n",
    "        \n",
    "        round_test_accuracy, round_test_loss=test(all_final_weights, test_loader)# distribution=f'clients_no_{client_no}_data_non-IID_CIFAR10_alpha_0.5'\n",
    "        print(f\"Model's Round: {r}, test accuracy of model: {round_test_accuracy}, test loss of model: {round_test_loss}\")\n",
    "        \n",
    "        list_accuracy.append(round_train_accuracy)\n",
    "        list_loss.append(round_train_loss)\n",
    "        list_test_accuracy.append(round_test_accuracy)\n",
    "        list_test_loss.append(round_test_loss)\n",
    "        \n",
    "        #model deviation code\n",
    "        round_rmd= 0 #model_deviation_function(i_w, all_final_weights)\n",
    "        #print(\"Model deviation values: \", model_deviation)\n",
    "        \n",
    "        #saving data into dataframe\n",
    "        round_data = [round_train_accuracy, round_train_loss, round_test_accuracy, round_test_loss, round_rmd, round_epoch, flri]\n",
    "        round_results.loc[len(round_results)] = round_data\n",
    "        \n",
    "        global_model.load_state_dict(all_final_weights)\n",
    "        print(\"round\", r, \"completed \\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8512e1d4",
   "metadata": {
    "id": "8512e1d4"
   },
   "source": [
    "# Main Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50345a9f",
   "metadata": {
    "id": "50345a9f"
   },
   "source": [
    "# Define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7fda6c6a",
   "metadata": {
    "id": "7fda6c6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's initial weights:conv1.weight: tensor([[ 0.1471,  0.1597, -0.0451],\n",
      "        [ 0.1768, -0.0422,  0.0388],\n",
      "        [-0.0937,  0.1130,  0.1697]], device='cuda:0')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#===========================Parameters==============================================================\n",
    "client_no=10\n",
    "participating_client=10\n",
    "epochs=5\n",
    "learning_rate=0.01\n",
    "round_no=60\n",
    "batch_size=64\n",
    "data_class=10\n",
    "\n",
    "opti=\"sgd\"\n",
    "# opti=\"adam\"\n",
    "\n",
    "mathod=\"fed_ed\"\n",
    "\n",
    "# set_up='IID'\n",
    "# set_up='non_IID'\n",
    "set_up='salt_pepper'\n",
    "# set_up='mislabelled'\n",
    "\n",
    "# iid\n",
    "# distribution=f\"clients_no_{client_no}_data_IID_CIFAR10_alpha_infinity\"\n",
    "\n",
    "#non_iid\n",
    "# distribution=f\"clients_no_{client_no}_data_IID_CIFAR10_alpha_0.1\"\n",
    "# distribution=f\"clients_no_{client_no}_data_IID_CIFAR10_alpha_0.5\"\n",
    "\n",
    "#salt_pepper\n",
    "# distribution=f\"clients_no_5_10_IID_CIFAR10_alpha_infinity_0.6\"\n",
    "# distribution=f\"clients_no_5_10_data_non-IID_CIFAR10_alpha_0.1_0.6\"\n",
    "distribution=f\"clients_no_5_10_data_non-IID_CIFAR10_alpha_0.5_0.6\"\n",
    "\n",
    "\n",
    "#misslabelled\n",
    "# distribution=f\"IID_clients_1_2_3_4_60pct_mislabeled_CIFAR10_infinity\"\n",
    "# distribution=f\"clients_1_2_3_4_60pct_mislabeled_CIFAR10_0.1\"\n",
    "# distribution=f\"clients_1_2_3_4_60pct_mislabeled_CIFAR10_0.5\"\n",
    "\n",
    "# List of clients\n",
    "total_clients_list = list(range(0, client_no))\n",
    "# print(total_clients_list)\n",
    "participating_client_list=[]\n",
    "\n",
    "# Define dataframe for round results\n",
    "round_columns = ['train_accuracy', 'train_loss', 'test_accuracy', 'test_loss', 'rmd', 'epoch', 'flri']\n",
    "round_results = pd.DataFrame(columns=round_columns)\n",
    "\n",
    "# Define dataframe for epoch results\n",
    "epoch_columns = ['round', 'client', 'train_accuracy', 'train_loss', 'test_accuracy', 'test_loss', 'rmd']\n",
    "epoch_results = pd.DataFrame(columns=epoch_columns)\n",
    "\n",
    "ad_client_values_list=[]\n",
    "\n",
    "list_accuracy=[]\n",
    "list_loss=[]\n",
    "list_test_accuracy=[]\n",
    "list_test_loss=[]\n",
    "\n",
    "\n",
    "delta_ad={}\n",
    "weight_c={}\n",
    "\n",
    "#===================================loading the saved weight list====================================================\n",
    "global_model = model().to(device)\n",
    "file_path= \"i_w.pth\"\n",
    "initial_weights = {k: v.clone() for k, v in global_model.state_dict().items()}\n",
    "torch.save(initial_weights, file_path)\n",
    "initial_weights=torch.load(file_path,weights_only=False)\n",
    "Print(\"Model's initial weights\", initial_weights)\n",
    "\n",
    "folder_name = f\"{mathod}_{opti}_lr={learning_rate}_R={round_no}_E={epochs}_B={batch_size}_{distribution}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aaecb98-d9ca-4153-b4f2-ea2289dab1bb",
   "metadata": {},
   "source": [
    "# Dataset loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c57ad45-e343-44d3-9ac7-1bc97ed5b28e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 0 - Total Samples: 5000 - Class Distribution: {0: 500, 1: 500, 2: 500, 3: 500, 4: 500, 5: 500, 6: 500, 7: 500, 8: 500, 9: 500}\n",
      "Client 1 - Total Samples: 5000 - Class Distribution: {0: 500, 1: 500, 2: 500, 3: 500, 4: 500, 5: 500, 6: 500, 7: 500, 8: 500, 9: 500}\n",
      "Client 2 - Total Samples: 5000 - Class Distribution: {0: 500, 1: 500, 2: 500, 3: 500, 4: 500, 5: 500, 6: 500, 7: 500, 8: 500, 9: 500}\n",
      "Client 3 - Total Samples: 5000 - Class Distribution: {0: 500, 1: 500, 2: 500, 3: 500, 4: 500, 5: 500, 6: 500, 7: 500, 8: 500, 9: 500}\n",
      "Client 4 - Total Samples: 5000 - Class Distribution: {0: 500, 1: 500, 2: 500, 3: 500, 4: 500, 5: 500, 6: 500, 7: 500, 8: 500, 9: 500}\n",
      "Client 5 - Total Samples: 5000 - Class Distribution: {0: 500, 1: 500, 2: 500, 3: 500, 4: 500, 5: 500, 6: 500, 7: 500, 8: 500, 9: 500}\n",
      "Client 6 - Total Samples: 5000 - Class Distribution: {0: 500, 1: 500, 2: 500, 3: 500, 4: 500, 5: 500, 6: 500, 7: 500, 8: 500, 9: 500}\n",
      "Client 7 - Total Samples: 5000 - Class Distribution: {0: 500, 1: 500, 2: 500, 3: 500, 4: 500, 5: 500, 6: 500, 7: 500, 8: 500, 9: 500}\n",
      "Client 8 - Total Samples: 5000 - Class Distribution: {0: 500, 1: 500, 2: 500, 3: 500, 4: 500, 5: 500, 6: 500, 7: 500, 8: 500, 9: 500}\n",
      "Client 9 - Total Samples: 5000 - Class Distribution: {0: 500, 1: 500, 2: 500, 3: 500, 4: 500, 5: 500, 6: 500, 7: 500, 8: 500, 9: 500}\n"
     ]
    }
   ],
   "source": [
    "def print_data_distribution(clients_data):\n",
    "    \"\"\"\n",
    "    Print the distribution of class labels for each client.\n",
    "    \"\"\"\n",
    "    for idx, client in enumerate(clients_data):\n",
    "        labels = [label for (_, label) in client]\n",
    "        class_counts = Counter(labels)\n",
    "        sorted_counts = dict(sorted(class_counts.items()))\n",
    "        print(f\"Client {idx} - Total Samples: {len(labels)} - Class Distribution: {sorted_counts}\")\n",
    "\n",
    "\n",
    "pt_path = os.path.join(f'{set_up}', f'{distribution}.pt')\n",
    "\n",
    "client_datasets = torch.load(pt_path)\n",
    "\n",
    "print_data_distribution(client_datasets)\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "# Define test set transformations for CIFAR-10 (no augmentation, just normalization)\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465),  # mean for CIFAR-10\n",
    "                         (0.2023, 0.1994, 0.2010))  # std for CIFAR-10\n",
    "])\n",
    "# Load CIFAR-10 test dataset\n",
    "cifar10_test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=test_transform)\n",
    "# Create DataLoader for the test set\n",
    "test_loader = DataLoader(cifar10_test_dataset, batch_size=32, shuffle=False, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec69f6d-2802-4aff-8fdc-d8371495125a",
   "metadata": {},
   "source": [
    "<H1>Round zero</H1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "516b645b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial_weights:conv1.weight: tensor([[ 0.1471,  0.1597, -0.0451],\n",
      "        [ 0.1768, -0.0422,  0.0388],\n",
      "        [-0.0937,  0.1130,  0.1697]], device='cuda:0')\n",
      "\n",
      " train accuracy: 9.994066455696203\n",
      " train_loss: 2.302823704405676\n",
      " test_accuracy: 10.093849840255592\n",
      " test_loss: 2.3028393766750543\n"
     ]
    }
   ],
   "source": [
    "#train accuracy for clients\n",
    "round_train_accuracy=0\n",
    "round_train_loss=0\n",
    "train_accuracy_list=[]\n",
    "train_loss_list=[]\n",
    "for c, data in enumerate(client_datasets):\n",
    "    train_loader = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=True)\n",
    "    train_accuracy, train_loss=test(initial_weights, train_loader)\n",
    "    train_accuracy_list.append(train_accuracy)\n",
    "    train_loss_list.append(train_loss)\n",
    "round_train_accuracy=(sum(train_accuracy_list)/len(train_accuracy_list))\n",
    "round_train_loss=(sum(train_loss_list)/len(train_loss_list))\n",
    "\n",
    "\n",
    "list_accuracy.append(round_train_accuracy)\n",
    "list_loss.append(round_train_loss)\n",
    "\n",
    "#test accuracy for server\n",
    "round_test_accuracy=0\n",
    "round_test_loss=0\n",
    "test_accuracy,test_loss=test(initial_weights,test_loader)\n",
    "# val_accuracy,val_loss=test(initial_weights,val_loader)\n",
    "\n",
    "# print(f\"{test_accuracy}, {test_loss}, {val_accuracy}, {val_loss}  \")\n",
    "round_test_accuracy=(test_accuracy)\n",
    "round_test_loss=(test_loss)\n",
    "\n",
    "round_rmd=0\n",
    "round_epoch=0\n",
    "\n",
    "round_data = [round_train_accuracy, round_train_loss, round_test_accuracy, round_test_loss, round_rmd, round_epoch, 0]\n",
    "round_results.loc[len(round_results)] = round_data\n",
    "\n",
    "# list_val_accuracy.append(val_accuracy)\n",
    "# list_val_loss.append(val_loss)\n",
    "list_test_accuracy.append(test_accuracy)\n",
    "list_test_loss.append(test_loss)\n",
    "\n",
    "\n",
    "Print(\"initial_weights\", initial_weights)\n",
    "print(f' train accuracy: {round_train_accuracy}\\n train_loss: {round_train_loss}\\n test_accuracy: {round_test_accuracy}\\n test_loss: {round_test_loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c3444a",
   "metadata": {},
   "source": [
    "<H1>Run FL</H1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "NJ_CpP0b9OUo",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NJ_CpP0b9OUo",
    "outputId": "961d3fb1-5fee-4497-be83-fff67f5e10e3",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " Model's Round: 1, train accuracy of model: 10.540000000000001, train loss of model: 2.3022051530548286\n",
      "Model's Round: 1, test accuracy of model: 10.153753993610223, test loss of model: 2.3021597831774825\n",
      "round 1 completed \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Model's Round: 2, train accuracy of model: 11.977999999999998, train loss of model: 2.300143111506595\n",
      "Model's Round: 2, test accuracy of model: 11.441693290734824, test loss of model: 2.2988637422982117\n",
      "round 2 completed \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Model's Round: 3, train accuracy of model: 12.474, train loss of model: 2.2809657468071465\n",
      "Model's Round: 3, test accuracy of model: 12.73961661341853, test loss of model: 2.2519283972609156\n",
      "round 3 completed \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Model's Round: 4, train accuracy of model: 23.848000000000003, train loss of model: 2.1061582255967055\n",
      "Model's Round: 4, test accuracy of model: 25.638977635782748, test loss of model: 2.4074236744889816\n",
      "round 4 completed \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Model's Round: 5, train accuracy of model: 26.939999999999998, train loss of model: 2.001055237462249\n",
      "Model's Round: 5, test accuracy of model: 27.42611821086262, test loss of model: 2.5130034506130525\n",
      "round 5 completed \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Model's Round: 6, train accuracy of model: 29.968, train loss of model: 1.9385891365099557\n",
      "Model's Round: 6, test accuracy of model: 29.952076677316295, test loss of model: 2.355185155670483\n",
      "round 6 completed \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Model's Round: 7, train accuracy of model: 32.41, train loss of model: 1.876980121678944\n",
      "Model's Round: 7, test accuracy of model: 31.240015974440894, test loss of model: 2.4456966589814937\n",
      "round 7 completed \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Model's Round: 8, train accuracy of model: 34.782000000000004, train loss of model: 1.8219138024728507\n",
      "Model's Round: 8, test accuracy of model: 32.697683706070286, test loss of model: 2.531728718608332\n",
      "round 8 completed \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Model's Round: 9, train accuracy of model: 36.426, train loss of model: 1.777557976185521\n",
      "Model's Round: 9, test accuracy of model: 33.18690095846645, test loss of model: 2.55218908504937\n",
      "round 9 completed \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Model's Round: 10, train accuracy of model: 38.089999999999996, train loss of model: 1.7345702845839006\n",
      "Model's Round: 10, test accuracy of model: 32.79752396166134, test loss of model: 2.6024835025921416\n",
      "round 10 completed \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Model's Round: 11, train accuracy of model: 39.288, train loss of model: 1.6948723443701297\n",
      "Model's Round: 11, test accuracy of model: 29.61261980830671, test loss of model: 2.9432673385729804\n",
      "round 11 completed \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Model's Round: 12, train accuracy of model: 40.344, train loss of model: 1.6612907599799243\n",
      "Model's Round: 12, test accuracy of model: 27.246405750798722, test loss of model: 3.176093775624284\n",
      "round 12 completed \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Model's Round: 13, train accuracy of model: 41.54600000000001, train loss of model: 1.6245908353902117\n",
      "Model's Round: 13, test accuracy of model: 27.006789137380192, test loss of model: 3.2901137252204333\n",
      "round 13 completed \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Model's Round: 14, train accuracy of model: 42.41199999999999, train loss of model: 1.5938558857652205\n",
      "Model's Round: 14, test accuracy of model: 26.72723642172524, test loss of model: 3.7057761605174395\n",
      "round 14 completed \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Model's Round: 15, train accuracy of model: 43.66199999999999, train loss of model: 1.562102580523189\n",
      "Model's Round: 15, test accuracy of model: 26.128194888178914, test loss of model: 4.113498354872195\n",
      "round 15 completed \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Model's Round: 16, train accuracy of model: 44.57000000000001, train loss of model: 1.539299750931655\n",
      "Model's Round: 16, test accuracy of model: 26.81709265175719, test loss of model: 4.23083142426829\n",
      "round 16 completed \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Model's Round: 17, train accuracy of model: 45.275999999999996, train loss of model: 1.5159808063808875\n",
      "Model's Round: 17, test accuracy of model: 25.888578274760384, test loss of model: 4.753731560021544\n",
      "round 17 completed \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Model's Round: 18, train accuracy of model: 46.146, train loss of model: 1.4884562361089488\n",
      "Model's Round: 18, test accuracy of model: 25.34944089456869, test loss of model: 5.109035005965553\n",
      "round 18 completed \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Model's Round: 19, train accuracy of model: 47.212, train loss of model: 1.4707544109489343\n",
      "Model's Round: 19, test accuracy of model: 26.218051118210862, test loss of model: 4.950659261343959\n",
      "round 19 completed \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Model's Round: 20, train accuracy of model: 48.004, train loss of model: 1.4435062721560272\n",
      "Model's Round: 20, test accuracy of model: 26.85702875399361, test loss of model: 4.949615556211136\n",
      "round 20 completed \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Model's Round: 21, train accuracy of model: 48.94199999999999, train loss of model: 1.4202984786486321\n",
      "Model's Round: 21, test accuracy of model: 25.299520766773163, test loss of model: 5.391657234380801\n",
      "round 21 completed \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Model's Round: 22, train accuracy of model: 49.456, train loss of model: 1.4030086684830578\n",
      "Model's Round: 22, test accuracy of model: 25.099840255591054, test loss of model: 5.773490904238277\n",
      "round 22 completed \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Model's Round: 23, train accuracy of model: 50.077999999999996, train loss of model: 1.3847450736957263\n",
      "Model's Round: 23, test accuracy of model: 24.790335463258785, test loss of model: 5.918770947014562\n",
      "round 23 completed \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Model's Round: 24, train accuracy of model: 51.302, train loss of model: 1.3664503003223034\n",
      "Model's Round: 24, test accuracy of model: 26.54752396166134, test loss of model: 5.940058875769472\n",
      "round 24 completed \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Model's Round: 25, train accuracy of model: 51.696000000000005, train loss of model: 1.3482461629789086\n",
      "Model's Round: 25, test accuracy of model: 27.246405750798722, test loss of model: 5.770980037439364\n",
      "round 25 completed \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Model's Round: 26, train accuracy of model: 52.641999999999996, train loss of model: 1.3209065184563022\n",
      "Model's Round: 26, test accuracy of model: 26.048322683706072, test loss of model: 6.063589526441532\n",
      "round 26 completed \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Model's Round: 27, train accuracy of model: 53.01800000000001, train loss of model: 1.30701222751714\n",
      "Model's Round: 27, test accuracy of model: 26.15814696485623, test loss of model: 6.141721415443542\n",
      "round 27 completed \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Model's Round: 28, train accuracy of model: 54.034000000000006, train loss of model: 1.2817440496215335\n",
      "Model's Round: 28, test accuracy of model: 28.75399361022364, test loss of model: 5.835311639042327\n",
      "round 28 completed \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Model's Round: 29, train accuracy of model: 54.565999999999995, train loss of model: 1.2621128992189334\n",
      "Model's Round: 29, test accuracy of model: 27.805511182108628, test loss of model: 6.289388392299128\n",
      "round 29 completed \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Model's Round: 30, train accuracy of model: 55.53800000000001, train loss of model: 1.2430727904355978\n",
      "Model's Round: 30, test accuracy of model: 24.810303514376997, test loss of model: 6.746567750510316\n",
      "round 30 completed \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Model's Round: 31, train accuracy of model: 56.436, train loss of model: 1.2176772334530384\n",
      "Model's Round: 31, test accuracy of model: 28.80391373801917, test loss of model: 6.235855580137941\n",
      "round 31 completed \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Model's Round: 32, train accuracy of model: 57.169999999999995, train loss of model: 1.2024205419081675\n",
      "Model's Round: 32, test accuracy of model: 28.833865814696484, test loss of model: 6.182832266956853\n",
      "round 32 completed \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Model's Round: 33, train accuracy of model: 57.7, train loss of model: 1.1832631573646881\n",
      "Model's Round: 33, test accuracy of model: 28.534345047923324, test loss of model: 6.446284586629167\n",
      "round 33 completed \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Model's Round: 34, train accuracy of model: 58.49399999999999, train loss of model: 1.1606908248949654\n",
      "Model's Round: 34, test accuracy of model: 29.63258785942492, test loss of model: 6.441643602170122\n",
      "round 34 completed \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Model's Round: 35, train accuracy of model: 59.08200000000001, train loss of model: 1.1367124075753783\n",
      "Model's Round: 35, test accuracy of model: 29.15335463258786, test loss of model: 6.275592125261935\n",
      "round 35 completed \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Model's Round: 36, train accuracy of model: 60.378, train loss of model: 1.1125301146431812\n",
      "Model's Round: 36, test accuracy of model: 27.715654952076676, test loss of model: 6.880102924645518\n",
      "round 36 completed \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Model's Round: 37, train accuracy of model: 61.008, train loss of model: 1.1041544741467584\n",
      "Model's Round: 37, test accuracy of model: 27.505990415335464, test loss of model: 6.8121981377037955\n",
      "round 37 completed \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Model's Round: 38, train accuracy of model: 61.355999999999995, train loss of model: 1.082600367521938\n",
      "Model's Round: 38, test accuracy of model: 30.511182108626198, test loss of model: 6.196675207668219\n",
      "round 38 completed \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Model's Round: 39, train accuracy of model: 62.117999999999995, train loss of model: 1.0579831805410265\n",
      "Model's Round: 39, test accuracy of model: 32.138578274760384, test loss of model: 5.785105979480682\n",
      "round 39 completed \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Model's Round: 40, train accuracy of model: 62.85, train loss of model: 1.0363219163085842\n",
      "Model's Round: 40, test accuracy of model: 31.479632587859424, test loss of model: 5.939846085283322\n",
      "round 40 completed \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Model's Round: 41, train accuracy of model: 63.66200000000001, train loss of model: 1.0227773847459238\n",
      "Model's Round: 41, test accuracy of model: 34.06549520766773, test loss of model: 5.536636886505273\n",
      "round 41 completed \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Model's Round: 42, train accuracy of model: 64.272, train loss of model: 1.0003957491132278\n",
      "Model's Round: 42, test accuracy of model: 32.43809904153355, test loss of model: 5.978381409812659\n",
      "round 42 completed \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Model's Round: 43, train accuracy of model: 64.912, train loss of model: 0.9833825214754176\n",
      "Model's Round: 43, test accuracy of model: 32.56789137380192, test loss of model: 5.976629750797162\n",
      "round 43 completed \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Model's Round: 44, train accuracy of model: 65.792, train loss of model: 0.962202575387834\n",
      "Model's Round: 44, test accuracy of model: 33.67611821086262, test loss of model: 5.980831332861806\n",
      "round 44 completed \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Model's Round: 45, train accuracy of model: 66.346, train loss of model: 0.941174134423461\n",
      "Model's Round: 45, test accuracy of model: 34.43490415335463, test loss of model: 5.792404633360549\n",
      "round 45 completed \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Model's Round: 46, train accuracy of model: 66.876, train loss of model: 0.930652520626406\n",
      "Model's Round: 46, test accuracy of model: 34.35503194888179, test loss of model: 6.011571970991433\n",
      "round 46 completed \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Model's Round: 47, train accuracy of model: 67.322, train loss of model: 0.9115005898701994\n",
      "Model's Round: 47, test accuracy of model: 33.86581469648562, test loss of model: 5.9959693137830055\n",
      "round 47 completed \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Model's Round: 48, train accuracy of model: 68.45400000000001, train loss of model: 0.8865246074109138\n",
      "Model's Round: 48, test accuracy of model: 36.36182108626198, test loss of model: 5.804513647914313\n",
      "round 48 completed \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Model's Round: 49, train accuracy of model: 68.91999999999999, train loss of model: 0.8664826007583473\n",
      "Model's Round: 49, test accuracy of model: 36.06230031948882, test loss of model: 5.7032039355927004\n",
      "round 49 completed \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Model's Round: 50, train accuracy of model: 69.776, train loss of model: 0.8525391333088091\n",
      "Model's Round: 50, test accuracy of model: 38.34864217252396, test loss of model: 5.340312686971963\n",
      "round 50 completed \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Model's Round: 51, train accuracy of model: 70.45400000000002, train loss of model: 0.8363294609362566\n",
      "Model's Round: 51, test accuracy of model: 37.35023961661342, test loss of model: 5.76077532196959\n",
      "round 51 completed \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Model's Round: 52, train accuracy of model: 70.676, train loss of model: 0.825119342607788\n",
      "Model's Round: 52, test accuracy of model: 38.47843450479233, test loss of model: 5.393027926405398\n",
      "round 52 completed \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Model's Round: 53, train accuracy of model: 71.30599999999998, train loss of model: 0.8026554589407352\n",
      "Model's Round: 53, test accuracy of model: 39.32707667731629, test loss of model: 5.406181819141863\n",
      "round 53 completed \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Model's Round: 54, train accuracy of model: 71.90200000000002, train loss of model: 0.7867285449104973\n",
      "Model's Round: 54, test accuracy of model: 38.79792332268371, test loss of model: 5.63027116818169\n",
      "round 54 completed \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Model's Round: 55, train accuracy of model: 72.684, train loss of model: 0.7705786695208732\n",
      "Model's Round: 55, test accuracy of model: 39.13738019169329, test loss of model: 5.604025803434963\n",
      "round 55 completed \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Model's Round: 56, train accuracy of model: 73.314, train loss of model: 0.7485591813733306\n",
      "Model's Round: 56, test accuracy of model: 40.14576677316294, test loss of model: 5.342615804733179\n",
      "round 56 completed \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Model's Round: 57, train accuracy of model: 74.12200000000001, train loss of model: 0.7300380603422093\n",
      "Model's Round: 57, test accuracy of model: 38.03913738019169, test loss of model: 5.931983662870365\n",
      "round 57 completed \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Model's Round: 58, train accuracy of model: 74.28200000000001, train loss of model: 0.7257775726952131\n",
      "Model's Round: 58, test accuracy of model: 39.906150159744406, test loss of model: 5.575006256469141\n",
      "round 58 completed \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Model's Round: 59, train accuracy of model: 75.172, train loss of model: 0.7087238936484616\n",
      "Model's Round: 59, test accuracy of model: 42.26238019169329, test loss of model: 5.097468876610168\n",
      "round 59 completed \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Model's Round: 60, train accuracy of model: 75.39000000000001, train loss of model: 0.6886433627597893\n",
      "Model's Round: 60, test accuracy of model: 39.936102236421725, test loss of model: 5.883927678909545\n",
      "round 60 completed \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "federated_learning(initial_weights, client_datasets, client_no, participating_client, round_no, epochs, learning_rate, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "965e0cf0-d1b2-4007-8183-8889ecf8bb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder_name = f\"{mathod}_{opti}_lr={learning_rate}_R={round_no}_ E={epochs}_B={batch_size}_{distribution}\"\n",
    "fn_=f\"{mathod}_{opti}_E={epochs}_B={batch_size}_iid\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f39d23d8-9b82-462a-9b5d-f0bb0b253d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# def plot_train_test_accuracy(round_results, title, folder):\n",
    "#     rounds = list(range(0, len(round_results)))\n",
    "#     train_accuracies = round_results['train_accuracy'].tolist()\n",
    "#     test_accuracies = round_results['test_accuracy'].tolist()\n",
    "\n",
    "#     fig, ax = plt.subplots(figsize=(5, 3))\n",
    "#     ax.plot(rounds, train_accuracies, label='Train Accuracy', color='blue')\n",
    "#     ax.plot(rounds, test_accuracies, label='Test Accuracy', color='green')\n",
    "\n",
    "#     ax.set_xlabel(\"Round\")\n",
    "#     ax.set_ylabel(\"Server accuracy in %\")\n",
    "#     ax.set_title(title)\n",
    "#     ax.set_ylim(0, 100)\n",
    "#     ax.set_xlim(0, len(rounds))\n",
    "#     ax.set_xticks(range(0, len(rounds) + 2, 10))\n",
    "\n",
    "#     ax.spines['top'].set_visible(False)\n",
    "#     ax.spines['right'].set_visible(False)\n",
    "\n",
    "#     ax.grid(True)\n",
    "#     ax.legend()\n",
    "#     plt.tight_layout()\n",
    "#     os.makedirs(folder, exist_ok=True)\n",
    "#     filename = os.path.join(folder, f\"{title}.png\")\n",
    "#     plt.savefig(filename, dpi=300)\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def plot_flri(round_results, title, folder):\n",
    "#     rounds = list(range(0, len(round_results)))\n",
    "#     train_accuracies = round_results['flri'].tolist()\n",
    "#     print(train_accuracies)\n",
    "#     # test_accuracies = round_results['test_accuracy'].tolist()\n",
    "\n",
    "#     fig, ax = plt.subplots(figsize=(5, 3))\n",
    "#     ax.plot(rounds, train_accuracies, label='flri', color='blue')\n",
    "#     # ax.plot(rounds, test_accuracies, label='Test Accuracy', color='green')\n",
    "\n",
    "#     ax.set_xlabel(\"Round\")\n",
    "#     ax.set_ylabel(\"Server accuracy in %\")\n",
    "#     ax.set_title(title)\n",
    "#     ax.set_ylim(0, 2)\n",
    "#     ax.set_xlim(0, len(rounds))Amr found himself sidelined and held partially responsible for Uthman's death. He then allied with Mu'awiya, who was also seeking retribution for Uthman's death and challenging Caliph Ali's rule. Amr'\n",
    "#     ax.set_xticks(range(0, len(rounds) + 2, 10))\n",
    "\n",
    "#     ax.spines['top'].set_visible(False)\n",
    "#     ax.spines['right'].set_visible(False)\n",
    "\n",
    "#     ax.grid(True)\n",
    "#     ax.legend()\n",
    "#     plt.tight_layout()\n",
    "#     os.makedirs(folder, exist_ok=True)\n",
    "#     filename = os.path.join(folder, f\"{title}.png\")\n",
    "#     plt.savefig(filename, dpi=300)\n",
    "#     plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d4679dee-d382-42de-b288-6f8b6fbfa03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # title = f\"a) AD vs R for {fn_}\"\n",
    "# # plot_rounds_clients_ad(delta_ad, title, folder_name)\n",
    "\n",
    "# title = f\"Acc (%) vs R for {fn_}\"\n",
    "# plot_train_test_accuracy(round_results, title, folder_name)\n",
    "\n",
    "# title = f\"flri vs R for {fn_}\"\n",
    "# plot_flri(round_results, title, folder_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a91d029",
   "metadata": {},
   "source": [
    "# Reuslts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "675880bc-5112-4aa9-ae58-2745973ba414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] delta_ad saved at fed_ed_sgd_lr=0.01_R=60_E=5_B=64_clients_no_10_data_IID_CIFAR10_alpha_infinity/delta_ad_data.pt\n",
      "[] Loaded delta_ad from: fed_ed_sgd_lr=0.01_R=60_E=5_B=64_clients_no_10_data_IID_CIFAR10_alpha_infinity/delta_ad_data.pt\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "save_dir = folder_name  # your desired folder\n",
    "os.makedirs(save_dir, exist_ok=True)  # create folder if not exists\n",
    "\n",
    "save_path = os.path.join(save_dir, 'delta_ad_data.pt')\n",
    "torch.save(delta_ad, save_path)\n",
    "print(f\"[] delta_ad saved at {save_path}\")\n",
    "\n",
    "save_path = os.path.join(folder_name, 'delta_ad_data.pt')\n",
    "\n",
    "# Load the saved file\n",
    "if os.path.exists(save_path):\n",
    "    delta_ad_loaded = torch.load(save_path)\n",
    "    print(\"[] Loaded delta_ad from:\", save_path)\n",
    "    print(delta_ad_loaded)\n",
    "else:\n",
    "    print(\"[] File not found at:\", save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f6fa4db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame successfully written for round results.\n"
     ]
    }
   ],
   "source": [
    "# Round # Define the folder and file name\n",
    "# folder_name = f\"fed_avg_{opti}_{learning_rate}_{name}\"  # Folder where the Excel file will be saved\n",
    "file_name = \"round_results.xlsx\"\n",
    "\n",
    "# Check if the folder exists, if not, create it\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "    \n",
    "# Full path where the Excel file will be saved\n",
    "file_path = os.path.join(folder_name, file_name)\n",
    "\n",
    "round_results.to_excel(file_path, index=False)\n",
    "\n",
    "print(\"DataFrame successfully written for round results.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc1e6ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define the folder and file name\n",
    "# folder_name =  f\"fed_avg_{opti}_{learning_rate}_{name}\"   # Folder where the Excel file will be saved\n",
    "file_name = \"epoch_results.xlsx\"\n",
    "\n",
    "# Check if the folder exists, if not, create it\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "\n",
    "# Full path where the Excel file will be saved\n",
    "file_path = os.path.join(folder_name, file_name)\n",
    "\n",
    "epoch_results.to_excel(file_path, index=False)\n",
    "\n",
    "print(\"DataFrame successfully written for epoch results.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0fa9b0-6505-47fb-b777-2f49c5410b4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04119e25-3978-4c2f-8a71-5c2ced5cc71d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5968c07d-67f0-46fd-90d9-2e166dbff1cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2cfb5d-c5ac-42e0-9442-4c7b40e4db70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa899427-72dc-4cc3-85b7-9c62c5dcf259",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "7a26882b",
    "f40fd883",
    "bef90546"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
